{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπ Nettoyage et Traduction de Donn√©es MySQL - News & Tweets\n",
    "\n",
    "Ce notebook permet de **traduire**, **nettoyer** et **stocker** les donn√©es de **3 fichiers CSV** dans MySQL, ou simplement de **charger** les donn√©es d√©j√† trait√©es.\n",
    "\n",
    "## üìÅ Datasets trait√©s :\n",
    "1. **fake_news_dataset.csv** ‚Üí Table `news`\n",
    "2. **labeled_data.csv** ‚Üí Table `labeled`\n",
    "3. **FakeNewsNet.csv** ‚Üí Table `fakenewsnet`\n",
    "\n",
    "## ‚öôÔ∏è Modes de fonctionnement :\n",
    "\n",
    "### üîÑ Mode `process` :\n",
    "- Charge les fichiers CSV\n",
    "- Traduit vers la langue pivot (optionnel)\n",
    "- Nettoie et tokenise le texte\n",
    "- Stocke dans MySQL\n",
    "- **√Ä utiliser : La premi√®re fois ou pour retraiter**\n",
    "\n",
    "### üì• Mode `load` (par d√©faut) :\n",
    "- Charge directement depuis MySQL\n",
    "- **Beaucoup plus rapide** (pas de retraitement)\n",
    "- **√Ä utiliser : Pour travailler avec des donn√©es d√©j√† trait√©es**\n",
    "\n",
    "## üéØ Configuration simple :\n",
    "\n",
    "Dans la cellule de configuration, changez simplement :\n",
    "```python\n",
    "MODE = 'load'     # Pour charger depuis MySQL (rapide)\n",
    "MODE = 'process'  # Pour retraiter les donn√©es (long)\n",
    "```\n",
    "\n",
    "## ‚öôÔ∏è Fonctionnalit√©s :\n",
    "- üåç **Traduction automatique vers langue pivot** (anglais) avec d√©tection de langue\n",
    "- ‚úÖ **Syst√®me intelligent** : charge ou traite selon la disponibilit√©\n",
    "- ‚úÖ **√âvite les retraitements inutiles** : v√©rifie si les donn√©es existent d√©j√†\n",
    "- ‚úÖ Suppression des URLs, mentions, symboles, emojis\n",
    "- ‚úÖ Tokenization et lemmatisation (via NLTK)\n",
    "- ‚úÖ Suppression des stopwords\n",
    "- ‚úÖ Stockage automatique dans MySQL\n",
    "\n",
    "## üìä Colonnes g√©n√©r√©es (mode process) :\n",
    "- `text_translated` : Texte traduit en langue pivot\n",
    "- `text_cleaned` : Texte nettoy√© (sans URLs, ponctuation, etc.)\n",
    "- `text_processed` : Texte final (tokenis√©, lemmatis√©, sans stopwords)\n",
    "\n",
    "## üîß Configuration MySQL :\n",
    "- **Database:** `dataControl`\n",
    "- **User:** `root`\n",
    "- **Password:** *(vide)*\n",
    "\n",
    "## üì¶ D√©pendances requises :\n",
    "- `googletrans==4.0.0-rc1` : Pour la traduction\n",
    "- `langdetect` : Pour la d√©tection de langue\n",
    "\n",
    "## üöÄ Utilisation :\n",
    "1. **Premi√®re fois** : Mettez `MODE = 'process'` et ex√©cutez toutes les cellules\n",
    "2. **Fois suivantes** : Laissez `MODE = 'load'` (d√©faut) pour charger rapidement les donn√©es\n",
    "3. Acc√©dez aux donn√©es via le dictionnaire `dataframes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ INSTALLATION DES D√âPENDANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des packages n√©cessaires (√† ex√©cuter une seule fois)\n",
    "# !pip install googletrans==4.0.0-rc1 langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "from googletrans import Translator\n",
    "from langdetect import detect\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurtion Mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Connexion MySQL r√©ussie!\n"
     ]
    }
   ],
   "source": [
    "# Configuration de la connexion MySQL\n",
    "DB_USERNAME = 'root'\n",
    "DB_PASSWORD = ''\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '3306'\n",
    "DB_NAME = 'dataControl'\n",
    "\n",
    "connection_string = f'mysql+pymysql://{DB_USERNAME}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    with engine.connect() as conn:\n",
    "        print(\"‚úì Connexion MySQL r√©ussie!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erreur de connexion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFIGURATION DU TRAITEMENT\n",
      "======================================================================\n",
      "Mode s√©lectionn√©: LOAD\n",
      "  ‚Üí Les donn√©es seront charg√©es depuis MySQL\n",
      "Nombre de datasets: 3\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# PARAM√àTRES DE CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "# Mode de traitement : \n",
    "# - 'process' : Nettoyer et stocker les donn√©es (retraitement complet)\n",
    "# - 'load'    : Charger les donn√©es depuis MySQL (sans retraitement)\n",
    "MODE = 'load'  # Changer en 'process' pour retraiter les donn√©es\n",
    "\n",
    "# Options de traitement (utilis√©es seulement si MODE = 'process')\n",
    "CONFIG = {\n",
    "    'translate': True,          # Active/D√©sactive la traduction\n",
    "    'pivot_lang': 'en',        # Langue pivot pour la traduction\n",
    "    'force_reprocess': False,  # Si True, force le retraitement m√™me si la table existe\n",
    "}\n",
    "\n",
    "# Datasets √† traiter\n",
    "DATASETS = {\n",
    "    'news': {\n",
    "        'csv_path': 'data/fake_news_dataset.csv',\n",
    "        'text_column': 'text',\n",
    "        'table_name': 'news'\n",
    "    },\n",
    "    'labeled': {\n",
    "        'csv_path': 'data/labeled_data.csv',\n",
    "        'text_column': 'tweet',\n",
    "        'table_name': 'labeled'\n",
    "    },\n",
    "    'fakenewsnet': {\n",
    "        'csv_path': '../fakeData/FakeNewsNet.csv',\n",
    "        'text_column': 'title',\n",
    "        'table_name': 'fakenewsnet'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CONFIGURATION DU TRAITEMENT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Mode s√©lectionn√©: {MODE.upper()}\")\n",
    "if MODE == 'process':\n",
    "    print(f\"  ‚Üí Traduction: {'Activ√©e' if CONFIG['translate'] else 'D√©sactiv√©e'}\")\n",
    "    print(f\"  ‚Üí Langue pivot: {CONFIG['pivot_lang']}\")\n",
    "    print(f\"  ‚Üí Force retraitement: {CONFIG['force_reprocess']}\")\n",
    "else:\n",
    "    print(\"  ‚Üí Les donn√©es seront charg√©es depuis MySQL\")\n",
    "print(f\"Nombre de datasets: {len(DATASETS)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è CONFIGURATION DU TRAITEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéÆ CONFIGURATION - MODIFIEZ ICI\n",
    "\n",
    "**Changez simplement le `MODE` selon vos besoins :**\n",
    "\n",
    "- üîÑ **`MODE = 'process'`** : Retraite compl√®tement les donn√©es (1√®re fois ou mise √† jour)\n",
    "- üì• **`MODE = 'load'`** : Charge depuis MySQL (rapide, recommand√© apr√®s 1er traitement)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 1 : FONCTIONS DE BASE\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonctions de nettoyage d√©finies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Nettoie le texte en appliquant plusieurs transformations\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Conversion en minuscules\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Suppression des URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Suppression des mentions (@username) et hashtags (#hashtag)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Suppression des emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Suppression des chiffres\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Suppression de la ponctuation et symboles\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Suppression des espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    \"\"\"\n",
    "    Tokenise, lemmatise et supprime les stopwords\n",
    "    \"\"\"\n",
    "    if not text or len(text) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Initialiser le lemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Lemmatisation\n",
    "        lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        # Suppression des stopwords anglais\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Filtrer les mots courts et les stopwords\n",
    "        filtered = [word for word in lemmatized \n",
    "                   if word not in stop_words and len(word) > 2]\n",
    "        \n",
    "        return ' '.join(filtered)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"‚úì Fonctions de nettoyage d√©finies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonction de traduction d√©finie\n"
     ]
    }
   ],
   "source": [
    "# 1.3 - Fonction de traduction vers langue pivot\n",
    "\n",
    "def translate_to_pivot_language(text, pivot_lang='en', max_retries=3):\n",
    "    \"\"\"\n",
    "    Traduit le texte vers une langue pivot (par d√©faut: anglais)\n",
    "    \n",
    "    Param√®tres:\n",
    "    -----------\n",
    "    text : str\n",
    "        Texte √† traduire\n",
    "    pivot_lang : str\n",
    "        Code de la langue pivot (par d√©faut: 'en' pour anglais)\n",
    "    max_retries : int\n",
    "        Nombre maximum de tentatives en cas d'erreur\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    str\n",
    "        Texte traduit ou texte original si erreur\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Limiter la longueur du texte pour √©viter les timeouts\n",
    "    if len(text) > 5000:\n",
    "        text = text[:5000]\n",
    "    \n",
    "    try:\n",
    "        # D√©tecter la langue source\n",
    "        source_lang = detect(text)\n",
    "        \n",
    "        # Si d√©j√† dans la langue pivot, retourner tel quel (RAPIDE!)\n",
    "        if source_lang == pivot_lang:\n",
    "            return text\n",
    "        \n",
    "        # Traduire vers la langue pivot (LENT - API call)\n",
    "        translator = Translator()\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                translation = translator.translate(text, src=source_lang, dest=pivot_lang)\n",
    "                return translation.text\n",
    "            except Exception as retry_error:\n",
    "                if attempt == max_retries - 1:\n",
    "                    # Derni√®re tentative √©chou√©e, retourner le texte original\n",
    "                    return text\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        # En cas d'erreur de d√©tection ou autre, retourner le texte original\n",
    "        return text\n",
    "\n",
    "print(\"‚úì Fonction de traduction d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 2 : FONCTIONS UTILITAIRES MySQL\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonction de v√©rification de table d√©finie\n"
     ]
    }
   ],
   "source": [
    "# 2.1 - Fonction pour v√©rifier l'existence d'une table\n",
    "\n",
    "def table_exists(table_name, engine):\n",
    "    \"\"\"\n",
    "    V√©rifie si une table existe dans MySQL\n",
    "    \n",
    "    Param√®tres:\n",
    "    -----------\n",
    "    table_name : str\n",
    "        Nom de la table √† v√©rifier\n",
    "    engine : SQLAlchemy Engine\n",
    "        Connexion √† la base de donn√©es\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    bool\n",
    "        True si la table existe, False sinon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = f\"SHOW TABLES LIKE '{table_name}'\"\n",
    "        result = pd.read_sql(query, engine)\n",
    "        return not result.empty\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "print(\"‚úì Fonction de v√©rification de table d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonction de chargement d√©finie\n"
     ]
    }
   ],
   "source": [
    "# 2.2 - Fonction pour charger les donn√©es depuis MySQL\n",
    "\n",
    "def load_dataset_from_mysql(table_name, engine):  \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"CHARGEMENT DEPUIS MYSQL - Table '{table_name}'\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # V√©rifier si la table existe\n",
    "        if not table_exists(table_name, engine):\n",
    "            print(f\"‚úó Table '{table_name}' n'existe pas dans la base de donn√©es\")\n",
    "            return None\n",
    "        \n",
    "        # Charger les donn√©es\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table_name}\", engine)\n",
    "        \n",
    "        print(f\"‚úì Donn√©es charg√©es: {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "        print(f\"  Colonnes: {list(df.columns)}\")\n",
    "        \n",
    "        # Afficher un aper√ßu\n",
    "        print(f\"\\nüìã Aper√ßu des donn√©es:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Fonction de chargement d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 3 : FONCTIONS DE TRAITEMENT COMPLET\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö DOCUMENTATION DES FONCTIONS\n",
    "\n",
    "### Section 1 : Fonctions de Base\n",
    "1. **`clean_text(text)`** - Nettoie le texte (URLs, ponctuation, etc.)\n",
    "2. **`tokenize_and_lemmatize(text)`** - Tokenise et lemmatise le texte\n",
    "3. **`translate_to_pivot_language(text, pivot_lang='en')`** - Traduit vers langue pivot\n",
    "\n",
    "### Section 2 : Fonctions Utilitaires MySQL\n",
    "1. **`table_exists(table_name, engine)`** - V√©rifie si une table existe\n",
    "2. **`load_dataset_from_mysql(table_name, engine)`** - Charge depuis MySQL\n",
    "\n",
    "### Section 3 : Fonctions de Traitement Complet\n",
    "1. **`process_and_store_dataset(...)`** - Traite compl√®tement un dataset (CSV ‚Üí MySQL)\n",
    "2. **`get_or_process_dataset(...)`** - Fonction intelligente (charge ou traite selon le mode)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonction intelligente de gestion d√©finie\n"
     ]
    }
   ],
   "source": [
    "# 3.2 - Fonction intelligente de gestion des donn√©es\n",
    "\n",
    "def get_or_process_dataset(\n",
    "    csv_path,\n",
    "    text_column,\n",
    "    table_name,\n",
    "    engine,\n",
    "    mode='load',\n",
    "    translate=True,\n",
    "    pivot_lang='en',\n",
    "    force_reprocess=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Fonction intelligente qui charge depuis MySQL ou traite les donn√©es selon le mode\n",
    "    \n",
    "    Param√®tres:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        Chemin vers le fichier CSV\n",
    "    text_column : str\n",
    "        Nom de la colonne contenant le texte √† nettoyer\n",
    "    table_name : str\n",
    "        Nom de la table MySQL\n",
    "    engine : SQLAlchemy Engine\n",
    "        Connexion √† la base de donn√©es\n",
    "    mode : str\n",
    "        'load' pour charger depuis MySQL, 'process' pour retraiter\n",
    "    translate : bool\n",
    "        Si True, traduit le texte vers la langue pivot (mode process uniquement)\n",
    "    pivot_lang : str\n",
    "        Code de la langue pivot\n",
    "    force_reprocess : bool\n",
    "        Si True, force le retraitement m√™me si la table existe\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    pandas.DataFrame ou None\n",
    "        DataFrame charg√©/trait√© si succ√®s, None si erreur\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mode LOAD : Charger depuis MySQL\n",
    "    if mode == 'load':\n",
    "        # V√©rifier si la table existe\n",
    "        if table_exists(table_name, engine):\n",
    "            print(f\"\\nüîç Mode LOAD activ√© pour '{table_name}'\")\n",
    "            return load_dataset_from_mysql(table_name, engine)\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Table '{table_name}' introuvable en mode LOAD\")\n",
    "            print(f\"üí° Basculement automatique en mode PROCESS...\")\n",
    "            mode = 'process'\n",
    "    \n",
    "    # Mode PROCESS : Traiter les donn√©es\n",
    "    if mode == 'process':\n",
    "        # V√©rifier si la table existe d√©j√†\n",
    "        if table_exists(table_name, engine) and not force_reprocess:\n",
    "            print(f\"\\n‚ö†Ô∏è Table '{table_name}' existe d√©j√†\")\n",
    "            response = input(f\"Voulez-vous la retraiter ? (o/n) : \").lower()\n",
    "            if response != 'o':\n",
    "                print(\"‚Üí Chargement des donn√©es existantes...\")\n",
    "                return load_dataset_from_mysql(table_name, engine)\n",
    "        \n",
    "        print(f\"\\nüîÑ Mode PROCESS activ√© pour '{table_name}'\")\n",
    "        return process_and_store_dataset(\n",
    "            csv_path=csv_path,\n",
    "            text_column=text_column,\n",
    "            table_name=table_name,\n",
    "            engine=engine,\n",
    "            translate=translate,\n",
    "            pivot_lang=pivot_lang\n",
    "        )\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"‚úì Fonction intelligente de gestion d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fonction de traitement g√©n√©rique d√©finie\n"
     ]
    }
   ],
   "source": [
    "def process_and_store_dataset(\n",
    "    csv_path, \n",
    "    text_column, \n",
    "    table_name, \n",
    "    engine,\n",
    "    translate=True,\n",
    "    pivot_lang='en',\n",
    "    additional_columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Fonction g√©n√©rique pour charger, traduire, nettoyer et stocker un dataset dans MySQL\n",
    "    \n",
    "    Param√®tres:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        Chemin vers le fichier CSV\n",
    "    text_column : str\n",
    "        Nom de la colonne contenant le texte √† nettoyer\n",
    "    table_name : str\n",
    "        Nom de la table MySQL o√π stocker les donn√©es\n",
    "    engine : SQLAlchemy Engine\n",
    "        Connexion √† la base de donn√©es\n",
    "    translate : bool\n",
    "        Si True, traduit le texte vers la langue pivot\n",
    "    pivot_lang : str\n",
    "        Code de la langue pivot (par d√©faut: 'en' pour anglais)\n",
    "    additional_columns : list, optional\n",
    "        Liste des colonnes suppl√©mentaires √† conserver\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    pandas.DataFrame ou None\n",
    "        DataFrame nettoy√© si succ√®s, None si erreur\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"TRAITEMENT DE: {csv_path}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ===== √âTAPE 1: CHARGEMENT =====\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"‚úì Fichier charg√©: {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "        print(f\"  Colonnes disponibles: {list(df.columns)}\")\n",
    "        print(f\"\\nüìÑ Aper√ßu des donn√©es brutes:\")\n",
    "        print(df.head(2))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚úó Fichier non trouv√©: {csv_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # ===== √âTAPE 2: V√âRIFICATION DE LA COLONNE =====\n",
    "    if text_column not in df.columns:\n",
    "        print(f\"‚úó Colonne '{text_column}' non trouv√©e!\")\n",
    "        print(f\"  Colonnes disponibles: {list(df.columns)}\")\n",
    "        return None\n",
    "    \n",
    "    # ===== √âTAPE 3: TRADUCTION (optionnelle) =====\n",
    "    if translate:\n",
    "        print(f\"\\n‚ñ∂ Traduction vers la langue pivot: '{pivot_lang}'\")\n",
    "        print(\"  ‚Üí Traduction en cours (peut prendre du temps)...\")\n",
    "        \n",
    "        # Limiter le nombre de lignes √† traduire pour le test (optionnel)\n",
    "        # On peut traiter toutes les lignes ou un √©chantillon\n",
    "        df['text_translated'] = df[text_column].apply(\n",
    "            lambda x: translate_to_pivot_language(x, pivot_lang=pivot_lang)\n",
    "        )\n",
    "        \n",
    "        print(f\"  ‚Üí Traduction termin√©e!\")\n",
    "        \n",
    "        # Utiliser la colonne traduite pour le nettoyage\n",
    "        text_to_clean = 'text_translated'\n",
    "    else:\n",
    "        text_to_clean = text_column\n",
    "    \n",
    "    # ===== √âTAPE 4: NETTOYAGE =====\n",
    "    print(f\"\\n‚ñ∂ Nettoyage de la colonne: '{text_to_clean}'\")\n",
    "    \n",
    "    # √âtape 4.1: Nettoyage de base\n",
    "    print(\"  ‚Üí Suppression URLs, mentions, ponctuation...\")\n",
    "    df['text_cleaned'] = df[text_to_clean].apply(clean_text)\n",
    "    \n",
    "    # √âtape 4.2: Tokenization et lemmatisation\n",
    "    print(\"  ‚Üí Tokenization et lemmatisation...\")\n",
    "    df['text_processed'] = df['text_cleaned'].apply(tokenize_and_lemmatize)\n",
    "    \n",
    "    # √âtape 4.3: Supprimer les lignes vides apr√®s nettoyage\n",
    "    initial_rows = df.shape[0]\n",
    "    df = df[df['text_processed'].str.len() > 0]\n",
    "    final_rows = df.shape[0]\n",
    "    \n",
    "    print(f\"  ‚Üí Lignes supprim√©es (vides): {initial_rows - final_rows}\")\n",
    "    print(f\"  ‚Üí Lignes finales: {final_rows}\")\n",
    "    \n",
    "    # Afficher un exemple de transformation\n",
    "    if final_rows > 0:\n",
    "        print(\"\\nüìä Exemple de transformation:\")\n",
    "        sample_idx = 0\n",
    "        original = str(df.iloc[sample_idx][text_column])\n",
    "        print(f\"  Texte original: {original[:120]}...\")\n",
    "        \n",
    "        if translate:\n",
    "            print(f\"  Texte traduit: {df.iloc[sample_idx]['text_translated'][:120]}...\")\n",
    "        \n",
    "        print(f\"  Texte nettoy√©: {df.iloc[sample_idx]['text_cleaned'][:120]}...\")\n",
    "        print(f\"  Texte trait√©: {df.iloc[sample_idx]['text_processed'][:120]}...\")\n",
    "    \n",
    "    # ===== √âTAPE 5: STOCKAGE DANS MYSQL =====\n",
    "    print(f\"\\n‚ñ∂ Stockage dans MySQL - Table '{table_name}'\")\n",
    "    \n",
    "    try:\n",
    "        df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            if_exists='replace',\n",
    "            index=False,\n",
    "            chunksize=1000\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Donn√©es stock√©es avec succ√®s dans la table '{table_name}'\")\n",
    "        \n",
    "        # V√©rification\n",
    "        result = pd.read_sql(f\"SELECT COUNT(*) as count FROM {table_name}\", engine)\n",
    "        print(f\"‚úì Nombre de lignes dans la table: {result['count'][0]}\")\n",
    "        \n",
    "        # Aper√ßu de la table\n",
    "        print(f\"\\nüìã Aper√ßu de la table '{table_name}':\")\n",
    "        preview = pd.read_sql(f\"SELECT * FROM {table_name} LIMIT 3\", engine)\n",
    "        print(preview.head())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Erreur lors du stockage: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Fonction de traitement g√©n√©rique d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAITEMENT DES DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù IMPORTANT : √Ä propos de la traduction\n",
    "\n",
    "### Comment √ßa fonctionne ?\n",
    "- Chaque texte est **automatiquement d√©tect√©** pour sa langue d'origine\n",
    "- Si le texte n'est **pas en anglais**, il est traduit automatiquement\n",
    "- Si le texte est **d√©j√† en anglais**, il reste inchang√©\n",
    "- La traduction est stock√©e dans la colonne `text_translated`\n",
    "\n",
    "### Param√®tres modifiables :\n",
    "- `translate=True/False` : Active ou d√©sactive la traduction\n",
    "- `pivot_lang='en'` : Langue pivot (peut √™tre 'fr', 'es', 'de', etc.)\n",
    "\n",
    "### ‚ö†Ô∏è Note sur les performances :\n",
    "La traduction peut prendre du temps pour de grands datasets. Pour tester rapidement :\n",
    "- R√©duisez le nombre de lignes : `df.head(100)` avant de traiter\n",
    "- Ou d√©sactivez la traduction : `translate=False`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö° OPTIMISATION DE LA TRADUCTION\n",
    "\n",
    "### üéØ Choix de la langue pivot :\n",
    "\n",
    "**Important** : V√©rifiez la langue de vos donn√©es AVANT de choisir `pivot_lang` !\n",
    "\n",
    "#### ‚úÖ **Si vos donn√©es sont EN ANGLAIS** (cas actuel) :\n",
    "```python\n",
    "pivot_lang='en'  # ‚ö° RAPIDE : Pas de traduction n√©cessaire!\n",
    "```\n",
    "\n",
    "#### ‚è≥ **Si vos donn√©es sont EN FRAN√áAIS** :\n",
    "```python\n",
    "pivot_lang='fr'  # üêå LENT : Traduit tout vers le fran√ßais\n",
    "```\n",
    "\n",
    "### üí° Pourquoi c'est important ?\n",
    "\n",
    "- **Donn√©es en anglais + `pivot_lang='en'`** ‚Üí ‚ö° **Instantan√©** (d√©tection seulement)\n",
    "- **Donn√©es en anglais + `pivot_lang='fr'`** ‚Üí üêå **Tr√®s lent** (traduit 20,000+ lignes!)\n",
    "\n",
    "### üîç Comment v√©rifier la langue de vos donn√©es ?\n",
    "\n",
    "Regardez quelques lignes de votre CSV. Si le texte est en anglais ‚Üí utilisez `'en'`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAITEMENT DE: data/fake_news_dataset.csv\n",
      "======================================================================\n",
      "‚úì Fichier charg√©: 20000 lignes, 7 colonnes\n",
      "  Colonnes disponibles: ['title', 'text', 'date', 'source', 'author', 'category', 'label']\n",
      "\n",
      "üìÑ Aper√ßu des donn√©es brutes:\n",
      "                                 title  \\\n",
      "0              Foreign Democrat final.   \n",
      "1  To offer down resource great point.   \n",
      "\n",
      "                                                text        date    source  \\\n",
      "0  more tax development both store agreement lawy...  2023-03-10  NY Times   \n",
      "1  probably guess western behind likely next inve...  2022-05-25  Fox News   \n",
      "\n",
      "         author  category label  \n",
      "0  Paula George  Politics  real  \n",
      "1   Joseph Hill  Politics  fake  \n",
      "\n",
      "‚ñ∂ Traduction vers la langue pivot: 'fr'\n",
      "  ‚Üí Traduction en cours (peut prendre du temps)...\n"
     ]
    }
   ],
   "source": [
    "# ===== DATASET 1: fake_news_dataset.csv =====\n",
    "df_fake_news = process_and_store_dataset(\n",
    "    csv_path='data/fake_news_dataset.csv',\n",
    "    text_column='text',\n",
    "    table_name='news',\n",
    "    engine=engine,\n",
    "    translate=True,  # Active la traduction\n",
    "    pivot_lang='fr'  # Langue pivot: anglais\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è±Ô∏è Temps de traitement estim√© :\n",
    "\n",
    "**Avec `pivot_lang='en'` (donn√©es en anglais)** :\n",
    "- ‚ö° **~5 secondes** pour 20,000 lignes (d√©tection seulement)\n",
    "\n",
    "**Avec `pivot_lang='fr'` (traduction n√©cessaire)** :\n",
    "- üêå **~30-60 minutes** pour 20,000 lignes (traduction compl√®te via API)\n",
    "- Chaque ligne = 1 appel API = ~0.1-0.2 seconde\n",
    "\n",
    "üí° **Astuce** : Testez d'abord sur un petit √©chantillon !\n",
    "```python\n",
    "df = df.head(100)  # Teste sur 100 lignes seulement\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
